{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arrow_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qXaQUJAFpy-n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/allisonhorst/\"\n",
        "                 \"palmerpenguins/47a3476d2147080e7ceccef4cf70105c808f2cbf/\"\n",
        "                 \"data-raw/penguins_raw.csv\")\n",
        "                 # Increase dataset to 1m rows and reset index\n",
        "df = df.sample(1_000_000, replace=True).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Update sample number (0 to 999'999)\n",
        "df[\"Sample Number\"] = df.index\n",
        "# Add some random variation to numeric columns\n",
        "df[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \n",
        "    \"Flipper Length (mm)\", \"Body Mass (g)\"]] = df[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \n",
        "                                                   \"Flipper Length (mm)\", \"Body Mass (g)\"]] \\\n",
        "                                               + np.random.rand(df.shape[0], 4)"
      ],
      "metadata": {
        "id": "5bkY7gbxunn2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write to csv\n",
        "df.to_csv(\"penguin-dataset.csv\")"
      ],
      "metadata": {
        "id": "l1Cpkvo7uyW4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiMxNgvXvSkW",
        "outputId": "508c1a53-5adf-42a5-e94d-502f52571a67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "# Write to Arrow\n",
        "# Convert from pandas to Arrow\n",
        "table = pa.Table.from_pandas(df)\n",
        "# Write out to file\n",
        "with pa.OSFile('penguin-dataset.arrow', 'wb') as sink:\n",
        "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
        "        writer.write_table(table)"
      ],
      "metadata": {
        "id": "iHDCWdozvJXf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe where missing numeric values are filled with zero\n",
        "df_nonan = df.copy()\n",
        "df_nonan[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \n",
        "          \"Flipper Length (mm)\", \"Body Mass (g)\"]] = df[[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \n",
        "                                                         \"Flipper Length (mm)\", \"Body Mass (g)\"]].fillna(0)"
      ],
      "metadata": {
        "id": "ytcgTKoLvdtm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from no-NaN pandas to Arrow\n",
        "table_nonan = pa.Table.from_pandas(df_nonan)\n",
        "# Write out to file\n",
        "with pa.OSFile('penguin-dataset-nonan.arrow', 'wb') as sink:\n",
        "    with pa.RecordBatchFileWriter(sink, table_nonan.schema) as writer:\n",
        "        writer.write_table(table_nonan)"
      ],
      "metadata": {
        "id": "z6MvNbB4vrZn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "sz = Path('penguin-dataset.csv').stat().st_size\n",
        "print(sz)\n",
        "\n",
        "from pathlib import Path\n",
        "sz = Path('penguin-dataset.arrow').stat().st_size\n",
        "print(sz)\n",
        "\n",
        "from pathlib import Path\n",
        "sz = Path('penguin-dataset-nonan.arrow').stat().st_size\n",
        "print(sz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7HUZOWxwdk9",
        "outputId": "2c5280dc-89c5-415c-c4fd-1bcd6159d26d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217220910\n",
            "197875410\n",
            "197375410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between reading memory-mapped Arrow files with and without zero-copying 2 times performance improvement shown below"
      ],
      "metadata": {
        "id": "7kecvLWmO5oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read csv and calculate mean\n",
        "%%timeit\n",
        "pd.read_csv(\"penguin-dataset.csv\")[\"Flipper Length (mm)\"].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6HybD-Ywi1u",
        "outputId": "f15df4ba-e7fd-4ddc-cb8d-ca4d13a29de3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.64 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Arrow using file API and calculate mean\n",
        "%%timeit\n",
        "with pa.OSFile('penguin-dataset.arrow', 'rb') as source:\n",
        "    table = pa.ipc.open_file(source).read_all().column(\"Flipper Length (mm)\")\n",
        "result = table.to_pandas().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8ep2Aw9x9Qz",
        "outputId": "765813f2-cc24-4e6a-85f9-4a58a41228e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 54.7 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Arrow with memory-mapped API with missing values\n",
        "%%timeit\n",
        "source = pa.memory_map('penguin-dataset.arrow', 'r')\n",
        "table = pa.ipc.RecordBatchFileReader(source).read_all().column(\"Flipper Length (mm)\")\n",
        "result = table.to_pandas().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBK3AG_PyII6",
        "outputId": "0ce0da12-5119-4190-969b-f2807d90ba2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 4.56 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Arrow with memory-mapped API without missing values (zero-copy)\n",
        "%%timeit\n",
        "source = pa.memory_map('penguin-dataset-nonan.arrow', 'r')\n",
        "table = pa.ipc.RecordBatchFileReader(source).read_all().column(\"Flipper Length (mm)\")\n",
        "result = table.to_pandas().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMw0r5SrycTr",
        "outputId": "a8b5eb24-a1e2-497c-ca9e-b069d2ca64f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 2.66 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install psutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpX9-bnSzYzc",
        "outputId": "bd305b82-9f57-4f94-ccf4-f0f03d73220c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "# Measure initial memory consumption\n",
        "memory_init = psutil.Process(os.getpid()).memory_info().rss >> 20\n",
        "\n",
        "\n",
        "# Read csv\n",
        "col_csv = pd.read_csv(\"penguin-dataset.csv\")[\"Flipper Length (mm)\"]\n",
        "memory_post_csv = psutil.Process(os.getpid()).memory_info().rss >> 20\n",
        "\n",
        "\n",
        "# Read Arrow using file API\n",
        "with pa.OSFile('penguin-dataset.arrow', 'rb') as source:\n",
        "    col_arrow_file = pa.ipc.open_file(source).read_all().column(\"Flipper Length (mm)\").to_pandas()\n",
        "memory_post_arrowos = psutil.Process(os.getpid()).memory_info().rss >> 20\n",
        "\n",
        "\n",
        "# Read Arrow with memory-mapped API with missing values\n",
        "source = pa.memory_map('penguin-dataset.arrow', 'r')\n",
        "table_mmap = pa.ipc.RecordBatchFileReader(source).read_all().column(\"Flipper Length (mm)\")\n",
        "col_arrow_mapped = table_mmap.to_pandas()\n",
        "memory_post_arrowmmap = psutil.Process(os.getpid()).memory_info().rss >> 20\n",
        "\n",
        "\n",
        "# Read Arrow with memory-mapped API without missing values (zero-copy)\n",
        "source = pa.memory_map('penguin-dataset-nonan.arrow', 'r')\n",
        "table_mmap_zc = pa.ipc.RecordBatchFileReader(source).read_all().column(\"Flipper Length (mm)\")\n",
        "col_arrow_mapped_zc = table_mmap_zc.to_pandas()\n",
        "memory_post_arrowmmap_zc = psutil.Process(os.getpid()).memory_info().rss >> 20\n",
        "\n",
        "\n",
        "# Display memory consumption - memory_init\n",
        "print(f\"initial memory consumption: {memory_init}\\n\")\n",
        "print(f\"csv memory consumption: {memory_post_csv}\\n\"\n",
        "f\"Arrow file memory consumption: {memory_post_arrowos - memory_post_csv}\\n\"\n",
        "      f\"Arrow mapped (no zero-copy) memory consumption: {memory_post_arrowmmap - memory_post_arrowos}\\n\"\n",
        "      f\"Arrow mapped (zero-copy) memory consumption: {memory_post_arrowmmap_zc - memory_post_arrowmmap}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfgzvmjpyizf",
        "outputId": "ac6215bd-e713-47f8-d259-3d4d628910fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial memory consumption: 1137\n",
            "\n",
            "csv memory consumption: 1195\n",
            "Arrow file memory consumption: 197\n",
            "Arrow mapped (no zero-copy) memory consumption: 5\n",
            "Arrow mapped (zero-copy) memory consumption: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the memory-mapping function and with filled NaN values, the pandas DataFrame was created directly on top of the stored Arrow file. No copying: 0 MB of RAM"
      ],
      "metadata": {
        "id": "CRrBgPR8PKoq"
      }
    }
  ]
}